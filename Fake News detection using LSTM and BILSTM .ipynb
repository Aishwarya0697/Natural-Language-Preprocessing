{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aishwarya\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Embedding, LSTM , Bidirectional\n",
    "from keras.layers import Dense , Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\\\Users\\\\Aishwarya\\\\Desktop\\\\sourabh\\\\Fake-News-Classifier-BiLSTM-master\\\\Fake-News-Classifier-BiLSTM-master\\\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the NAN Values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting of data into independent and dependent feauture\n",
    "x = df.drop(\"label\", axis = 1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10361\n",
       "1     7924\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index of our dataset as we drop the null values from our dataset\n",
    "messages = x.copy()\n",
    "messages.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'title', 'author', 'text'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aishwarya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub()\n",
    "#Replace with regular expression\n",
    "#Replace multiple substrings with the same string\n",
    "#Replace using the matched part\n",
    "#Get the count of replaced parts\n",
    "#Here we are going to replace all regural expression which are not between a to z or A to Z with whitespace.\n",
    "\n",
    "#result.lower:\n",
    "#By this we are going to replace all the words in Lower case,So that all are treated as equally\n",
    "\n",
    "#ps.stem()\n",
    "#Stemming is the process of producing morphological variants of a root/base word. Stemming programs are\n",
    "#commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0 , len(messages)):\n",
    "    review = re.sub(\"[^a-zA-Z]\",\" \", messages[\"title\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words(\"english\")]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri',\n",
       " 'jacki mason hollywood would love trump bomb north korea lack tran bathroom exclus video breitbart',\n",
       " 'beno hamon win french socialist parti presidenti nomin new york time',\n",
       " 'back channel plan ukrain russia courtesi trump associ new york time',\n",
       " 'obama organ action partner soro link indivis disrupt trump agenda',\n",
       " 'bbc comedi sketch real housew isi caus outrag',\n",
       " 'russian research discov secret nazi militari base treasur hunter arctic photo',\n",
       " 'us offici see link trump russia',\n",
       " 'ye paid govern troll social media blog forum websit',\n",
       " 'major leagu soccer argentin find home success new york time',\n",
       " 'well fargo chief abruptli step new york time']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4156, 1491, 633, 4426, 1651, 2218, 412, 3362, 2021, 712],\n",
       " [1064, 635, 1489, 3863, 353, 2167, 4932],\n",
       " [4999, 1670, 3858, 3448],\n",
       " [1640, 3061, 4204, 3256, 2614, 3586],\n",
       " [1596, 353, 4467, 4281, 2361, 2003, 353, 76, 4221, 4988]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr = [one_hot(words,5000) for words in corpus]\n",
    "onehot_repr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4156, 1491,  633, ...,    0,    0,    0],\n",
       "       [1064,  635, 1489, ...,    0,    0,    0],\n",
       "       [4999, 1670, 3858, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1219, 3820, 4745, ...,    0,    0,    0],\n",
       "       [1202,  893, 4346, ...,    0,    0,    0],\n",
       "       [2611, 4702,  972, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_length = 30\n",
    "embeded_docs = pad_sequences(onehot_repr,padding= 'post',maxlen = sent_length)\n",
    "embeded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4156, 1491,  633, 4426, 1651, 2218,  412, 3362, 2021,  712,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embeded_docs)\n",
    "Y= np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embedding_vector_features, input_length = sent_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3511 - accuracy: 0.8203 - val_loss: 0.2077 - val_accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.1404 - accuracy: 0.9469 - val_loss: 0.2398 - val_accuracy: 0.9172\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0989 - accuracy: 0.9666 - val_loss: 0.2419 - val_accuracy: 0.9158\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.0749 - accuracy: 0.9745 - val_loss: 0.2558 - val_accuracy: 0.9147\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.3258 - val_accuracy: 0.9131\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.3836 - val_accuracy: 0.9079\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0371 - accuracy: 0.9894 - val_loss: 0.2976 - val_accuracy: 0.9069\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.3983 - val_accuracy: 0.9045\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.3717 - val_accuracy: 0.9121\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.4742 - val_accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee96025cc8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-fdaaf2360398>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2814,  293],\n",
       "       [ 217, 2162]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907036091870215"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 40)            200000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               112800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 313,001\n",
      "Trainable params: 313,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(5000, embedding_vector_features, input_length = sent_length))\n",
    "model1.add(Bidirectional(LSTM(100)))\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.3081 - accuracy: 0.8538 - val_loss: 0.1903 - val_accuracy: 0.9225\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.1324 - accuracy: 0.9519 - val_loss: 0.1937 - val_accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.0915 - accuracy: 0.9691 - val_loss: 0.2237 - val_accuracy: 0.9176\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.0643 - accuracy: 0.9786 - val_loss: 0.2633 - val_accuracy: 0.9152\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.3496 - val_accuracy: 0.9076\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.3346 - val_accuracy: 0.9136\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.3767 - val_accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.3732 - val_accuracy: 0.9141\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.4451 - val_accuracy: 0.9076\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.4754 - val_accuracy: 0.9116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee9a4e4708>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2822,  285],\n",
       "       [ 200, 2179]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115931461903026"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
